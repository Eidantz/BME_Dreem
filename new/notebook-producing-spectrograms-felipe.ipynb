{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006603,
     "end_time": "2021-01-01T17:43:55.944275",
     "exception": false,
     "start_time": "2021-01-01T17:43:55.937672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dreem 2 Sleep Classification challenge 2020\n",
    "**Student: Felipe Cybis Pereira**\n",
    "\n",
    "This notebook produces multitaper spectrograms for each epoch and saves them as a new dataset to be used.\n",
    "\n",
    "By commiting this notebook, the output will be saved in Kaggle and will be possible to use as input data in a different Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-01T17:43:55.966234Z",
     "iopub.status.busy": "2021-01-01T17:43:55.965401Z",
     "iopub.status.idle": "2021-01-01T17:44:05.197093Z",
     "shell.execute_reply": "2021-01-01T17:44:05.196445Z"
    },
    "papermill": {
     "duration": 9.247676,
     "end_time": "2021-01-01T17:44:05.197227",
     "exception": false,
     "start_time": "2021-01-01T17:43:55.949551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dreem-2-sleep-classification-challenge-2020/sample_submission.csv\n",
      "/kaggle/input/dreem-2-sleep-classification-challenge-2020/y_train.csv\n",
      "/kaggle/input/dreem-2-sleep-classification-challenge-2020/X_train.h5/X_train.h5\n",
      "/kaggle/input/dreem-2-sleep-classification-challenge-2020/X_test.h5/X_test.h5\n",
      "Collecting lspopt\r\n",
      "  Downloading lspopt-1.1.1-py2.py3-none-any.whl (35 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from lspopt) (1.14.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lspopt) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lspopt) (1.4.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lspopt) (1.18.5)\r\n",
      "Installing collected packages: lspopt\r\n",
      "Successfully installed lspopt-1.1.1\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import h5py # Read and write HDF5 files from Python\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "# filenames\n",
    "data_path = \"/kaggle/input/dreem-2-sleep-classification-challenge-2020/\"\n",
    "file_xtrain = data_path + \"X_train.h5/X_train.h5\"\n",
    "file_xtest = data_path + \"X_test.h5/X_test.h5\"\n",
    "file_ytrain = data_path + \"y_train.csv\"\n",
    "\n",
    "! pip install lspopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-01T17:44:05.244210Z",
     "iopub.status.busy": "2021-01-01T17:44:05.242853Z",
     "iopub.status.idle": "2021-01-01T17:44:05.994871Z",
     "shell.execute_reply": "2021-01-01T17:44:05.993945Z"
    },
    "papermill": {
     "duration": 0.789328,
     "end_time": "2021-01-01T17:44:05.994982",
     "exception": false,
     "start_time": "2021-01-01T17:44:05.205654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lspopt import spectrogram_lspopt # function needed for multitaper spectrogram\n",
    "\n",
    "def normalize_data(eeg_array):\n",
    "    \"\"\"Normalizes signal between -1 and 1 by clipping data between -400 and 400 micro Volts\"\"\"\n",
    "\n",
    "    normalized_array = np.clip(eeg_array, -400, 400)\n",
    "    normalized_array = normalized_array / 400\n",
    "\n",
    "    return normalized_array\n",
    "\n",
    "def compute_spectrogram(eeg_data,\n",
    "                        fs = 50.,\n",
    "                        win_sec = 2.,\n",
    "                        fmin = 0.5,\n",
    "                        fmax = 20.,\n",
    "                        sec_overlap = 1.5,\n",
    "                        c_parameter=20.0):\n",
    "        \"\"\"\n",
    "        Compute spectrogram from EEG 1D-array\n",
    "            :param eeg_data (numpy 1D array): 1D numpy array of raw eeg data\n",
    "            :param fs (float): sampling frequency (default = 50 Hz)\n",
    "            :param win_sec (float): time of the taper windows (default = 2 sec)\n",
    "            :param fmin (float): lower bound of the frequencies to be returned in the spectrogram (default = 0.5 Hz)\n",
    "            :param fmax (float): higher bound of the frequencies to be returned in the spectrogram (default = 20.0 Hz)\n",
    "            :param sec_overlap (float): overlapping window in seconds (default = 1.5 sec)\n",
    "            :param c_parameter (float): C parameter as defined in doi:10.1155/2011/980805\n",
    "            \n",
    "            :return Sxx (numpy 2D array): Multitaper spectrogram\n",
    "            :return t (numpy 1D array): corresponding time array of the spectrogram\n",
    "            :return f (numpy 1D array): corresonding frequency array of the spectrogram\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate multi-taper spectrogram\n",
    "        nperseg = int(win_sec * fs)\n",
    "        noverlap = sec_overlap * fs\n",
    "        assert eeg_data.size > 2 * nperseg, 'Data length must be at least 2 * win_sec * fs (' +str(nperseg)+ '). It is ' + str(eeg_data.size)\n",
    "        f, t, Sxx = spectrogram_lspopt(eeg_data, fs, c_parameter, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "        Sxx = 10 * np.log10(Sxx)  # Convert uV^2 / Hz --> dB / Hz\n",
    "        Sxx[Sxx == np.inf] = 0\n",
    "        Sxx[Sxx == -np.inf] = 0\n",
    "\n",
    "        # Select only relevant frequencies (up to 30 Hz)\n",
    "        good_freqs = np.logical_and(f >= fmin, f <= fmax)\n",
    "        Sxx = Sxx[good_freqs, :]\n",
    "        f = f[good_freqs]\n",
    "\n",
    "        return Sxx, t, f\n",
    "    \n",
    "def get_data(file_path, derivation):\n",
    "    \"\"\"Get .h5 data from path\"\"\"\n",
    "    \n",
    "    with h5py.File(file_path, \"r\") as fi:\n",
    "        data = fi[derivation][()]\n",
    "        \n",
    "    return data\n",
    "    \n",
    "def get_spectrograms(file_path, channel_list=['eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7']):\n",
    "    \"\"\"Uses compute_spectrogram function to create new dataset of spectrograms\n",
    "        :param file_path (path): file path to get eeg raw data\n",
    "        :param channel_list (list): list of derivations to get from .h5 eeg file\n",
    "        \n",
    "        :return dict_with_spectrograms (dict): python dictionaire with spectrograms from `channel_list` as well as `index` and `index_window`\n",
    "    \"\"\"\n",
    "    \n",
    "    index = get_data(file_path, 'index')\n",
    "    index_window = get_data(file_path, 'index_window')\n",
    "    \n",
    "    # Init python dictionaire with keys for spectrograms\n",
    "    keys = ['Sxx_1', 'Sxx_2', 'Sxx_3', 'Sxx_4', 'Sxx_5', 'Sxx_6', 'Sxx_7']\n",
    "    dict_with_spectrograms = dict.fromkeys(keys)\n",
    "    dict_with_spectrograms['index'] = index\n",
    "    dict_with_spectrograms['index_window'] = index_window\n",
    "        \n",
    "    for channel, key in zip(channel_list, keys):\n",
    "        x_data = get_data(file_path, channel) # eeg raw data\n",
    "        subjects = np.unique(index) # subjects in training set\n",
    "        \n",
    "        list_of_Sxx = []\n",
    "        for subject in subjects:\n",
    "            print('Getting spectrogram from ' + channel + '. Subject ' + str(subject) + '...', end='\\r')\n",
    "            subject_data = x_data[index==subject]\n",
    "            \n",
    "            ## Params to compute spectrogram\n",
    "            fs = 50.\n",
    "            win_sec = 2.\n",
    "            fmin = 0.5\n",
    "            fmax = 20.\n",
    "            sec_overlap = 1.5\n",
    "            step_size = win_sec - sec_overlap\n",
    "            ## these parameters were chosen to result in spectrograms of 30 seconds of size (40x60)\n",
    "            \n",
    "            padding_size = int(win_sec / 2 / step_size)\n",
    "            Sxx_epoch_size = int(30 // step_size) # think about [0., 0.5, ..., 29.5]\n",
    "            \n",
    "            assert (win_sec / 2) % step_size == 0, 'For clean data shape, win_sec/2 should be div by step_size'\n",
    "            Sxx, _, _ = compute_spectrogram(subject_data.flatten(), fs, win_sec, fmin, fmax, sec_overlap)\n",
    "            \n",
    "            ## padding before and after spectrogram so that every epoch can have same dimensions!\n",
    "            padding_before = np.zeros((Sxx.shape[0], padding_size))\n",
    "            padding_after = np.zeros((Sxx.shape[0], padding_size-1))\n",
    "            \n",
    "            new_Sxx = np.append(padding_before, np.append(Sxx, padding_after, axis=1), axis=1)\n",
    "            assert new_Sxx.shape[-1] % Sxx_epoch_size == 0, 'Spectrogram has not the right shape, Sxx.shape=' + str(new_Sxx.shape)\n",
    "            \n",
    "            ## Sxx has shape (frequency_bins, time_bins) with time_bins going from first to last subject's epoch\n",
    "            new_Sxx_reshape = new_Sxx.reshape(new_Sxx.shape[0], subject_data.shape[0], -1)\n",
    "            ## now Sxx has shape (frequency_bins, num_epochs, time_bins) with time_bins for each epoch\n",
    "            new_Sxx_transpose = new_Sxx_reshape.transpose((1,0,2))\n",
    "            ## now Sxx has shape (num_epochs, frequency, time_bins)\n",
    "            list_of_Sxx += [new_Sxx_transpose]\n",
    "            \n",
    "        dict_with_spectrograms[key] = np.concatenate(list_of_Sxx, axis=0)\n",
    "        # now if the eeg data has 24688 epochs, each epoch with 1500 data points\n",
    "        # the Sxx data will have 24688 epochs, each epoch with (frequency_bins,time_bins) dimensions\n",
    "        # here Sxx will have dimensions (24688, 40, 60)\n",
    "    \n",
    "    return dict_with_spectrograms\n",
    "            \n",
    "def save_dict_as_h5py(dictionaire, filename):\n",
    "    \"\"\"Save python dictionaire as .h5 file\"\"\"\n",
    "    working_dir = os.getcwd()\n",
    "    \n",
    "    hf = h5py.File(os.path.join(working_dir, filename), 'w')\n",
    "    \n",
    "    for key, value in dictionaire.items():\n",
    "        hf.create_dataset(key, data=value)\n",
    "    \n",
    "    hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T17:44:06.025495Z",
     "iopub.status.busy": "2021-01-01T17:44:06.024845Z",
     "iopub.status.idle": "2021-01-01T17:46:25.042026Z",
     "shell.execute_reply": "2021-01-01T17:46:25.041275Z"
    },
    "papermill": {
     "duration": 139.039481,
     "end_time": "2021-01-01T17:46:25.042172",
     "exception": false,
     "start_time": "2021-01-01T17:44:06.002691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting spectrogram from eeg_7. Subject 30...\r"
     ]
    }
   ],
   "source": [
    "# Computing spectrograms of the training data\n",
    "dict_with_spectrograms = get_spectrograms(file_xtrain)\n",
    "save_dict_as_h5py(dict_with_spectrograms, 'Sxx_x_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T17:46:37.344618Z",
     "iopub.status.busy": "2021-01-01T17:46:37.343718Z",
     "iopub.status.idle": "2021-01-01T17:48:53.473354Z",
     "shell.execute_reply": "2021-01-01T17:48:53.472147Z"
    },
    "papermill": {
     "duration": 139.1195,
     "end_time": "2021-01-01T17:48:53.473566",
     "exception": false,
     "start_time": "2021-01-01T17:46:34.354066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting spectrogram from eeg_7. Subject 60...\r"
     ]
    }
   ],
   "source": [
    "# Computing spectrograms of the test data\n",
    "dict_with_spectrograms = get_spectrograms(file_xtest)\n",
    "save_dict_as_h5py(dict_with_spectrograms, 'Sxx_x_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T17:48:53.786301Z",
     "iopub.status.busy": "2021-01-01T17:48:53.785295Z",
     "iopub.status.idle": "2021-01-01T17:48:54.384535Z",
     "shell.execute_reply": "2021-01-01T17:48:54.385078Z"
    },
    "papermill": {
     "duration": 0.747358,
     "end_time": "2021-01-01T17:48:54.385234",
     "exception": false,
     "start_time": "2021-01-01T17:48:53.637876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving y data with the spectrograms as well, just to have all together \n",
    "y_data = pd.read_csv(file_ytrain) \n",
    "y_data.to_csv('y_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 32.030915,
     "end_time": "2021-01-01T17:49:26.546290",
     "exception": false,
     "start_time": "2021-01-01T17:48:54.515375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 335.453865,
   "end_time": "2021-01-01T17:49:26.777870",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-01T17:43:51.324005",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
