{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nimport optuna\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Conv1D, Dropout, MaxPool1D, LeakyReLU\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import KFold\nfrom scipy.interpolate import interp1d\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py # Read and write HDF5 files from Python\nimport os\nimport numpy as np\n\ndata_path = \"/kaggle/input/dreem-2-sleep-classification-challenge-2020/\"\nfile_xtrain = data_path + \"X_train.h5/X_train.h5\"\nfile_xtest = data_path + \"X_test.h5/X_test.h5\"\nfile_ytrain = data_path + \"y_train.csv\"\n# training labels\npd.read_csv(file_ytrain)\n# what does the h5 file contains ?\nwith h5py.File(file_xtrain, \"r\") as hf:\n        print(list(hf.keys()))\n\n# How to load data from h5? what is its shape and type?\nwith h5py.File(file_xtrain, \"r\") as hf:\n        field = list(hf.keys())[0]\n        x_data = hf[field][()]\ntype(x_data), x_data.shape\n\ndef normalize_data(eeg_array):\n    \"\"\"normalize signal between 0 and 1\"\"\"\n\n    normalized_array = np.clip(eeg_array, -150, 150)\n    normalized_array = normalized_array / 150\n\n    return normalized_array\n\ndef split_data(input_signals_list,validation_ratio=0.2):\n    with h5py.File(file_xtrain, \"r\") as fi:\n        if len(input_signals_list) == 1:\n            x_data = fi[input_signals_list[0]][()]\n        else:\n            x_data = np.zeros([24688,1500,len(input_signals_list)])\n            for i in range(0, len(input_signals_list)):\n                if 'x' in input_signals_list[i] or 'y' in input_signals_list[i] or 'z' in input_signals_list[i]:\n                    f1 = interp1d(np.arange(0, 300), fi[input_signals_list[i]][()], axis=1)\n                    xnew = np.linspace(0, 30, num=1500)\n                    x_data[0:24688, 0:1500, i] = f1(xnew)\n                else:\n                    x_data[0:24688, 0:1500, i] = fi[input_signals_list[i]][()]\n        y_data = pd.read_csv(file_ytrain)['sleep_stage'].to_numpy()\n        # Creating data indices for training and validation splits:\n        dataset_size = len(y_data)\n        indices = list(range(dataset_size))\n        split = int((1 - validation_ratio) * dataset_size)\n        np.random.shuffle(indices)\n        train_indices, val_indices = indices[:split], indices[split:]\n\n        x_train, x_validation = x_data[train_indices], x_data[val_indices]\n        y_train, y_validation = y_data[train_indices], y_data[val_indices]\n\n        x_train, x_validation = normalize_data(x_train), normalize_data(x_validation)\n\n    return x_train, y_train, x_validation, y_validation\ninput_signals_list = ['eeg_2','eeg_3','eeg_4','eeg_5','y']\n#input_signals_list = ['eeg_4','eeg_1']\n#input_signals_list = ['eeg_1', 'eeg_2', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7','y','x']\nx_train, y_train, x_validation, y_validation = split_data(input_signals_list)\n\n\n\n\n# Model configuration\nbatch_size = 32\nloss_function = sparse_categorical_crossentropy\nno_classes = 5\nno_epochs = 20\noptimizer = Adam(learning_rate=0.001)\nverbosity = 1\nnum_folds = 3\n\n# Determine shape of the data\n\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# Merge inputs and targets\ninputs = np.concatenate((x_train, x_validation), axis=0)\ntargets = np.concatenate((y_train, y_validation), axis=0)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(inputs, targets):\n\n  # Define the model architecture\n  model = Sequential()\n  model.add(Conv1D(128, kernel_size=7, strides=2, input_shape=(1500,len(input_signals_list))))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(Conv1D(128, kernel_size=7, strides=2))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(Dropout(0.5))\n  model.add(Conv1D(128, kernel_size=7, strides=2))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(MaxPool1D(4))\n  model.add(Conv1D(256, kernel_size=7, strides=2))\n  model.add(Conv1D(128, kernel_size=7, strides=2))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(Dropout(0.5))\n  model.add(Flatten())\n  model.add(Dense(256))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(Dense(128))\n  model.add(LeakyReLU(alpha=0.1))\n  model.add(Dense(no_classes, activation='softmax'))\n\n  # Compile the model\n  model.compile(loss=loss_function,\n                optimizer=optimizer,\n                metrics=['accuracy'])\n\n\n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n  history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              epochs=no_epochs,\n              verbose=verbosity)\n\n  # Generate generalization metrics\n  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n\n  # Increase fold number\n  fold_no = fold_no + 1\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}