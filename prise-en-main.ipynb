{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"id":"OK2WjGZ6xim0"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py # Read and write HDF5 files from Python\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/dreem-2-sleep-classification-challenge-2020/y_train.csv\n/kaggle/input/dreem-2-sleep-classification-challenge-2020/sample_submission.csv\n/kaggle/input/dreem-2-sleep-classification-challenge-2020/X_train.h5/X_train.h5\n/kaggle/input/dreem-2-sleep-classification-challenge-2020/X_test.h5/X_test.h5\n","name":"stdout"}]},{"metadata":{"id":"9ssg591Wxim_"},"cell_type":"markdown","source":"Now we are going into the Dreem 2 Challenge.\nThe goal is to use Dreem 2 headband data to perform sleep stage scoring on 30 seconds epochs of biophysiological signals.\nhttps://www.kaggle.com/c/ei-dreem-sleep-stages-2020/data\n\nThe training dataset is composed of:\n- X_train.h5: input Dreem2 headband data: 30s of biosignals including EEG and accelerometer\n- y_train: sleep stages {'Wake':0, 'N1':1, 'N2':2, 'N3':3, 'REM':4} \n\nThe challenge is to submit the sleep stages associated to:\n- X_test.h5\n(it has to be submitted in the right format, see sample_submission.csv)\n"},{"metadata":{"trusted":true,"id":"8MHxahAYxinA"},"cell_type":"code","source":"# filenames\ndata_path = \"/kaggle/input/dreem-2-sleep-classification-challenge-2020/\"\nfile_xtrain = data_path + \"X_train.h5/X_train.h5\"\nfile_xtest = data_path + \"X_test.h5/X_test.h5\"\nfile_ytrain = data_path + \"y_train.csv\"","execution_count":2,"outputs":[]},{"metadata":{"id":"rJ8wdSk6xinJ"},"cell_type":"markdown","source":"Let's have a look at the data"},{"metadata":{"trusted":true,"id":"2Y2M2IwOxinK"},"cell_type":"code","source":"# training labels\npd.read_csv(file_ytrain)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"       index  sleep_stage\n0          0            0\n1          1            0\n2          2            0\n3          3            0\n4          4            0\n...      ...          ...\n24683  24683            4\n24684  24684            0\n24685  24685            0\n24686  24686            0\n24687  24687            0\n\n[24688 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>sleep_stage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24683</th>\n      <td>24683</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>24684</th>\n      <td>24684</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24685</th>\n      <td>24685</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24686</th>\n      <td>24686</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24687</th>\n      <td>24687</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>24688 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"id":"pQyZXYWUxinR"},"cell_type":"code","source":"# what does the h5 file contains ?\nwith h5py.File(file_xtrain, \"r\") as hf:\n        print(list(hf.keys()))","execution_count":14,"outputs":[{"output_type":"stream","text":"['eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'index', 'index_absolute', 'index_window', 'pulse', 'x', 'y', 'z']\n","name":"stdout"}]},{"metadata":{"trusted":true,"id":"dg0KdddhxinW"},"cell_type":"code","source":"# How to load data from h5? what is its shape and type?\nwith h5py.File(file_xtrain, \"r\") as hf:\n\n        field = list(hf.keys())[0]\n        x_data = hf[field][:]\ntype(x_data), x_data.shape\n","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(numpy.ndarray, (24688, 1500))"},"metadata":{}}]},{"metadata":{"id":"A4JPBGU0xind"},"cell_type":"markdown","source":"In this TD, we will only work with one EEG channel.\nLet's create dataset functions that will be used for training and testing the model:\n\n*EegEpochDataset*: Eeg Class herited from pytorch Dataset to deal with our data\n\n*get_train_validation_dataset*: \n- return train_dataloader and validation_dataloader\n- dataloaders will be used during the training and the tests\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"uQOtPHbUxine"},"cell_type":"code","source":"\"\"\" Load project data\n    DataLoader and Dataset for single-channel EEG\n\n\"\"\"\nimport tensorflow as tf\n\n\ndef normalize_data(eeg_array):\n    \"\"\"normalize signal between 0 and 1\"\"\"\n\n    normalized_array = np.clip(eeg_array, -150, 150)\n    normalized_array = normalized_array / 150\n\n    return normalized_array\n\n\n\ndef get_train_validation_dataset(derivation, validation_ratio=0.2):\n    \"\"\"\n    Return train and validation datasets in Dataloader format\n    :param derivation: list EEG derivation, from eeg_1 to eeg_7\n    :param batch_size: size of the batch, usually 16, 32 or 64\n    :param validation_ratio:\n\n    :return:\n    train_dataloader\n    validation_dataloader\n    \"\"\"\n\n\n    # c'est moche a changé \n\n    with h5py.File(file_xtrain, \"r\") as fi:\n        x_data1 = fi[derivation[0]][()]\n        x_data2 = fi[derivation[1]][()]\n    \n    x_data = np.stack((x_data1,x_data2), axis=2)\n        \n    \n\n    y_data = pd.read_csv(file_ytrain)['sleep_stage'].to_numpy()\n\n            \n    print(x_data.shape)\n    \n\n    # Creating data indices for training and validation splits:\n    dataset_size = len(y_data)\n    \n    indices = list(range(dataset_size))\n    split = int((1 - validation_ratio) * dataset_size)\n    np.random.shuffle(indices)\n    train_indices, val_indices = indices[:split], indices[split:]\n\n    x_train, x_validation = x_data[train_indices], x_data[val_indices]\n    y_train, y_validation = y_data[train_indices], y_data[val_indices]\n\n    # torch dataset\n    \n\n    return x_train, x_validation , y_train, y_validation\n\n\n# load dataloaders - final_val is the dataset for the last validation\n#train_dataset, final_val_dataset = get_train_validation_dataset('eeg_5')\n\nx_train, x_validation , y_train, y_validation =  get_train_validation_dataset(['eeg_1','eeg_5'])\n\nprint(x_train.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"(24688, 1500, 2)\n(19750, 1500, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"r5fmw8OQxinj"},"cell_type":"markdown","source":"Now we create the neural network Model:\n- convolutionnal neural network\n- Fully conencted layers at the end\n- takes only a single channel of EEG signal as input"},{"metadata":{"trusted":true,"id":"jPAcxipDxinl"},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass SingleChannelConvNet(nn.Module):\n\n    def __init__(self):\n        super(SingleChannelConvNet, self).__init__()\n        # convolutionnal mayers\n        self.conv_a = nn.Conv1d(1, 128, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_b = nn.Conv1d(128, 128, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_c = nn.Conv1d(128, 256, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_d = nn.Conv1d(256, 256, 5, stride=2, padding=4, padding_mode='zeros')\n        self.conv_e = nn.Conv1d(256, 256, 3, stride=2, padding=2, padding_mode='zeros')\n\n        # pool layers\n        self.pool = nn.MaxPool1d(2)\n\n        # non linearity\n        self.activfunc_a = nn.LeakyReLU(negative_slope=0.1)\n\n        # fully connected layers - at the end\n        self.fc1 = nn.Linear(3 * 256, 100)\n        self.fc2 = nn.Linear(100, 5)\n\n    def forward(self, x):\n\n        x = self.activfunc_a(self.conv_a(x))\n        for _ in range(5):\n            x = self.activfunc_a(self.conv_b(x))\n        x = self.activfunc_a(self.conv_c(x))\n        for _ in range(3):\n            x = self.activfunc_a(self.conv_d(x))\n        x = self.activfunc_a(self.conv_e(x))\n        x = self.activfunc_a(self.conv_e(x))\n\n        x = x.view(-1, self.num_flat_features(x)) # flatten the tensor\n        x = self.activfunc_a(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv1D(128, 7, strides =2 , padding='same', activation=tf.nn.relu,  input_shape=(1500,2 )),\n    tf.keras.layers.Conv1D(128, 7, padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling1D((2), strides=2, data_format='channels_first'),\n\n    tf.keras.layers.Conv1D(128, 7,padding='same', activation=tf.nn.relu),\n    tf.keras.layers.Conv1D(256, 5, padding='same', activation=tf.nn.relu),\n    tf.keras.layers.Conv1D(256, 5, padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling1D((2),  data_format='channels_first'),\n    tf.keras.layers.Conv1D(256, 3,padding='same', activation=tf.nn.relu),\n    tf.keras.layers.Conv1D(256, 3, padding='same', activation=tf.nn.relu),\n    tf.keras.layers.Flatten(),\n\n    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n    tf.keras.layers.Dense(5, activation=\"softmax\")\n])\n\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nprint(model.summary())\nprint(x_train.shape)\n\nmodel.fit(x_train, y_train,batch_size=32, epochs=20, shuffle= True)\nmodel.evaluate(x_validation, y_validation)","execution_count":6,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_7 (Conv1D)            (None, 750, 128)          1920      \n_________________________________________________________________\nconv1d_8 (Conv1D)            (None, 750, 128)          114816    \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 750, 64)           0         \n_________________________________________________________________\nconv1d_9 (Conv1D)            (None, 750, 128)          57472     \n_________________________________________________________________\nconv1d_10 (Conv1D)           (None, 750, 256)          164096    \n_________________________________________________________________\nconv1d_11 (Conv1D)           (None, 750, 256)          327936    \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 750, 128)          0         \n_________________________________________________________________\nconv1d_12 (Conv1D)           (None, 750, 256)          98560     \n_________________________________________________________________\nconv1d_13 (Conv1D)           (None, 750, 256)          196864    \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 192000)            0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               49152256  \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_5 (Dense)              (None, 5)                 1285      \n=================================================================\nTotal params: 50,180,997\nTrainable params: 50,180,997\nNon-trainable params: 0\n_________________________________________________________________\nNone\n(19750, 1500, 2)\nEpoch 1/20\n618/618 [==============================] - 20s 33ms/step - loss: 1.6217 - accuracy: 0.1430\nEpoch 2/20\n618/618 [==============================] - 20s 32ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 3/20\n618/618 [==============================] - 20s 33ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 4/20\n618/618 [==============================] - 20s 33ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 5/20\n618/618 [==============================] - 20s 32ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 6/20\n618/618 [==============================] - 20s 33ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 7/20\n618/618 [==============================] - 20s 33ms/step - loss: 1.6094 - accuracy: 0.1429\nEpoch 8/20\n321/618 [==============>...............] - ETA: 9s - loss: 1.6094 - accuracy: 0.1452","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9745460ebd62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_validation.shape)","execution_count":30,"outputs":[{"output_type":"stream","text":"(4938, 2, 1500)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":9,"outputs":[{"output_type":"stream","text":"(19750, 1500)\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"Input 0 of layer conv1d_1 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: [19750, 1500]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-838bb806660d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2618\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2619\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d_1 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: [19750, 1500]"]}]},{"metadata":{"id":"OYm_atwwxinp"},"cell_type":"markdown","source":"You can now start the training on the train dataloader:\n- model will train many times on the dataset: n_epochs\n- training dataset will be split in three subset (k_fold cross-validation)\n- loss_val: mean loss on the validation datasets, computed after each epochs of training"},{"metadata":{"trusted":true,"id":"R5puDba5xinp"},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# device: use GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# parameters\nlearning_rate = 0.001\nn_epoch = 20\nk_fold = 3\nbatch_size = 32\n\n# neural network\nmy_net = SingleChannelConvNet()\nmy_net = my_net.to(device) # model into GPU\n# loss function\ncriterion = nn.CrossEntropyLoss()\n# optimisation algorithm \noptimizer = optim.Adam(my_net.parameters(), lr=learning_rate)\n\n\n# function: evaluate the loss of validation subset\ndef loss_val(net, val_loader):\n    with torch.no_grad(): # do not forget to remove gradient computing during evaluation !!!\n        val_loss = 0.0\n        for data in val_dataloader:\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n        return val_loss\n","execution_count":21,"outputs":[]},{"metadata":{"id":"7t3y4DlMxinu"},"cell_type":"markdown","source":"Let's start the loop !"},{"metadata":{"trusted":true,"_kg_hide-output":true,"id":"_Vdufdptxinv"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom torch.utils.data.dataset import Subset\nfrom torch.utils.data import DataLoader\n\n# List all the validation loss:\n# at the end of each epoch of training, a loss is computed on a subset of data\nall_val_loss = []\n\nprint('training...')\nfor epoch in range(n_epoch):  # loop over the dataset multiple times\n\n    # validation losses for this epoch (n=k_fold)\n    val_loss = []        \n    for train_indices, val_indices in KFold(n_splits=k_fold).split(list(range(len(train_dataset)))):\n        # k_fold dataloader (k=3) - Take validation subset for training, to avoid overfit\n        train_subset = Subset(train_dataset, train_indices)\n        val_subset = Subset(train_dataset, val_indices)\n\n        train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)\n        val_dataloader = DataLoader(val_subset, batch_size=batch_size, num_workers=8)\n\n        running_loss = 0.0\n        for i, data in enumerate(train_dataloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + loss + backward + optimize\n            outputs = my_net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:\n                print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss))\n            running_loss = 0.0\n\n        # average validation losses\n        val_loss += [loss_val(my_net, val_dataloader)]\n        \n    all_val_loss += [np.round(np.mean(val_loss), 2)]\n    print(all_val_loss)\n\n    \nprint('Finished Training')","execution_count":22,"outputs":[{"output_type":"stream","text":"training...\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'train_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4f1dded94b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# validation losses for this epoch (n=k_fold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# k_fold dataloader (k=3) - Take validation subset for training, to avoid overfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"]}]},{"metadata":{"trusted":true,"id":"wTOU98Gixinz"},"cell_type":"code","source":"from pprint import pprint\nfrom sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n\n# score function\ndef evaluate(true, pred):\n    scores = {'balanced_accuracy': balanced_accuracy_score(true, pred),\n            'cohen_kappa': cohen_kappa_score(true, pred),\n            'confusion_matrix': confusion_matrix(true, pred)}\n\n    return scores\n\n# params\nclasses = ['Wake', 'N1', 'N2', 'N3', 'REM']\n\n# final validation dataset: has not be used for the training\nval_dataloader = DataLoader(final_val_dataset, batch_size=batch_size, num_workers=8)\n\n# evaluate the performance of the model\nwith torch.no_grad():\n    prediction_list = torch.empty(0).to(device)\n    true_list = torch.empty(0).to(device)\n    for data in val_dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = my_net(inputs)\n        _, predicted = torch.max(outputs, 1)\n        prediction_list = torch.cat([prediction_list, predicted])\n        true_list = torch.cat([true_list, labels])\n\n        \n# Scores\ntrue_list = true_list.cpu().numpy()\nprediction_list = prediction_list.cpu().numpy()\nscores = evaluate(true_list, prediction_list)\n\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"id":"2G2pRC4Kxin3"},"cell_type":"markdown","source":"During the training, you may have noticed that you could have stopped earlier to have a lower validation, and maybe a better model at the end.\nRewrite the code to save the 3 models with the lower validation loss, and compare them on the final_validation_dataset !"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}